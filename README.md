# Emotion-Aware Customer Feedback Analysis with Explainable AI

[![CI/CD Pipeline](https://github.com/Petlaz/emotion-xai-project/workflows/CI%2FCD%20Pipeline/badge.svg)](https://github.com/Petlaz/emotion-xai-project/actions)
[![codecov](https://codecov.io/gh/Petlaz/emotion-xai-project/branch/main/graph/badge.svg)](https://codecov.io/gh/Petlaz/emotion-xai-project)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)

A comprehensive package for analyzing customer feedback using transformer models, explainable AI techniques, and clustering for theme discovery.

## Features

- **Multi-label emotion classification** using fine-tuned transformer models (DistilRoBERTa)
- **Explainable AI** with SHAP and LIME explanations for model interpretability
- **Theme discovery** through clustering analysis using UMAP + HDBSCAN
- **Interactive web interface** built with Gradio for real-time analysis
- **Comprehensive evaluation** metrics and visualizations
- **Production-ready** with Docker support and CI/CD pipelines

## Quick Start

### Installation

```bash
pip install emotion-xai
```

### Basic Usage

```python
from emotion_xai.data.preprocessing import load_dataset, prepare_features
from emotion_xai.models.baseline import BaselineModel
from emotion_xai.explainability.explanations import explain_with_shap
from emotion_xai.utils.device import resolve_device

# Setup device optimization (automatic detection: CUDA/MPS/CPU)
device = resolve_device()

# Load GoEmotions dataset (211,225 samples with 28 emotion labels)
data = load_dataset("data/raw/goemotions.csv")
features = prepare_features(data, "text")

# Train baseline model (TF-IDF + Logistic Regression)
model = BaselineModel()
model.fit(train_texts, train_labels)

# Evaluate model performance (Current: F1-macro 0.161)
metrics = model.evaluate(val_texts, val_labels)
print(f"F1-macro: {metrics['f1_macro']:.3f}")

# Generate explanations
explanations = explain_with_shap(model, sample_texts)
```

### Current Performance Benchmarks (Phase 1-2 Complete)

**Data Processing Pipeline:**
- **Dataset**: GoEmotions (211,225 â†’ 211,008 samples, 99.90% retention)
- **Quality Filtering**: 6 types of quality issues identified and handled
- **Train/Val/Test Split**: 70%/10%/20% (147,705/21,101/42,202 samples)

**Baseline Model Performance:**
- **Algorithm**: TF-IDF (10K features) + One-vs-Rest Logistic Regression
- **F1-Macro Score**: 0.161 (benchmark for transformer comparison)
- **Training Time**: ~10 seconds on Apple M1
- **Best Emotions**: Amusement (0.390), Admiration (0.356), Joy (0.319)
- **Challenging Emotions**: Annoyance (0.020), Approval (0.046), Caring (0.069)

### Advanced Training Configuration

```python
from emotion_xai.models.transformer import TrainingConfig, train_model

# Create training configuration
config = TrainingConfig(
    model_name="distilroberta-base",
    batch_size=16,
    learning_rate=2e-5,
    num_epochs=3,
    device=None  # Auto-detect best available device
)

# Train with automatic device optimization
trainer = train_model(config, train_dataset, eval_dataset)
```

## Project Structure

```
emotion_xai_project/
â”œâ”€â”€ emotion_xai/                 # ðŸ“¦ Main Python package (installable)
â”‚   â”œâ”€â”€ __init__.py             #    Package initialization & exports
â”‚   â”œâ”€â”€ cli.py                  #    Command-line interface entry point
â”‚   â”œâ”€â”€ data/                   #    ðŸ“ Data processing modules (Python code)
â”‚   â”‚   â”œâ”€â”€ __init__.py         #    NOT actual data - just processing code!
â”‚   â”‚   â””â”€â”€ preprocessing.py    #    Text cleaning & feature preparation functions
â”‚   â”œâ”€â”€ models/                 #    ðŸ¤– Machine learning models
â”‚   â”‚   â”œâ”€â”€ __init__.py         
â”‚   â”‚   â”œâ”€â”€ baseline.py         #    TF-IDF + Logistic Regression baseline
â”‚   â”‚   â””â”€â”€ transformer.py     #    DistilRoBERTa fine-tuning utilities
â”‚   â”œâ”€â”€ explainability/         #    ðŸ” Model interpretation & XAI
â”‚   â”‚   â”œâ”€â”€ __init__.py         
â”‚   â”‚   â””â”€â”€ explanations.py    #    SHAP & LIME explanation generators
â”‚   â”œâ”€â”€ clustering/             #    ðŸŽ¯ Theme discovery & clustering
â”‚   â”‚   â”œâ”€â”€ __init__.py         
â”‚   â”‚   â””â”€â”€ feedback_clustering.py  # UMAP + HDBSCAN clustering
â”‚   â””â”€â”€ utils/                  #    ðŸ› ï¸ Shared utilities & configuration
â”‚       â”œâ”€â”€ __init__.py         
â”‚       â”œâ”€â”€ config.py           #    Configuration management classes
â”‚       â””â”€â”€ device.py           #    Device detection and optimization utilities
â”‚
â”œâ”€â”€ tests/                      # ðŸ§ª Test suite (pytest-based)
â”‚   â”œâ”€â”€ conftest.py             #    Shared test fixtures & configuration
â”‚   â”œâ”€â”€ unit/                   #    Unit tests for individual modules
â”‚   â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”‚   â”œâ”€â”€ test_baseline.py
â”‚   â”‚   â””â”€â”€ test_device.py      #    Device optimization tests
â”‚   â”œâ”€â”€ integration/            #    Integration & end-to-end tests
â”‚   â”‚   â””â”€â”€ test_pipeline.py
â”‚   â””â”€â”€ fixtures/               #    Test data & mock objects
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ docs/                       # ðŸ“š Documentation (Markdown & Sphinx)
â”‚   â”œâ”€â”€ README.md               #    Documentation overview
â”‚   â”œâ”€â”€ getting_started.md      #    Installation & quick start guide
â”‚   â”œâ”€â”€ development.md          #    Development setup & contributing
â”‚   â””â”€â”€ documentation_report.md #    Project documentation report
â”‚
â”œâ”€â”€ config/                     # âš™ï¸ Configuration files (YAML-based)
â”‚   â”œâ”€â”€ default.yaml            #    Default configuration settings
â”‚   â”œâ”€â”€ development.yaml        #    Development environment config
â”‚   â””â”€â”€ production.yaml         #    Production environment config
â”‚
â”œâ”€â”€ data/                       # ðŸ’¾ ACTUAL data files (at project root)
â”‚   â”œâ”€â”€ raw/                    #    ðŸ“ Original datasets
â”‚   â”‚   â”œâ”€â”€ .gitkeep            #    (data files themselves are gitignored)
â”‚   â”‚   â””â”€â”€ goemotions.csv      #    âœ… GoEmotions dataset (211,225 samples, 28 emotions)
â”‚   â””â”€â”€ processed/              #    ðŸ“ Cleaned & preprocessed data files  
â”‚       â””â”€â”€ .gitkeep            #    (processed data files are gitignored)
â”‚
â”œâ”€â”€ models/                     # ðŸ¤– Saved model artifacts & checkpoints
â”‚   â”œâ”€â”€ distilroberta_finetuned/ #    Fine-tuned transformer models
â”‚   â”‚   â””â”€â”€ .gitkeep            #    (model files gitignored)
â”‚   â”œâ”€â”€ cluster_embeddings/     #    Clustering model artifacts
â”‚   â”‚   â””â”€â”€ .gitkeep            #    (model files gitignored)
â”‚   â””â”€â”€ .cache/                 #    HuggingFace model cache
â”‚
â”œâ”€â”€ notebooks/                  # ðŸ““ Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb    # EDA & data understanding
â”‚   â”œâ”€â”€ 02_modeling.ipynb            # âœ… Baseline modeling & preprocessing (COMPLETED)
â”‚   â”œâ”€â”€ 03_finetuning.ipynb          # Transformer fine-tuning experiments (NEXT)
â”‚   â”œâ”€â”€ 04_explainability.ipynb      # XAI analysis & visualization
â”‚   â””â”€â”€ 05_clustering_analysis.ipynb # Theme discovery analysis
â”‚
â”œâ”€â”€ app/                        # ðŸŒ Web application (Gradio interface)
â”‚   â””â”€â”€ gradio_app.py           #    Interactive demo & API server
â”‚
â”œâ”€â”€ docker/                     # ðŸ³ Containerization & deployment
â”‚   â”œâ”€â”€ Dockerfile              #    Multi-stage Docker build
â”‚   â””â”€â”€ requirements.txt        #    Docker-specific dependencies
â”‚
â”œâ”€â”€ scripts/                    # ðŸ› ï¸ Utility scripts for setup & automation
â”‚   â””â”€â”€ download_goemotions.py  #    GoEmotions dataset download utility
â”‚
â”œâ”€â”€ results/                    # ðŸ“Š Analysis results & outputs
â”‚   â”œâ”€â”€ README.md               #    Results overview & documentation
â”‚   â”œâ”€â”€ metrics/                #    ðŸ“ˆ EDA statistics, model performance, evaluations
â”‚   â”‚   â”œâ”€â”€ eda_statistics_*.json     # Comprehensive EDA findings
â”‚   â”‚   â”œâ”€â”€ emotion_distribution_*.csv # Emotion frequency analysis
â”‚   â”‚   â”œâ”€â”€ emotion_correlations_*.csv # Correlation matrices
â”‚   â”‚   â””â”€â”€ text_quality_assessment_*.csv # Data quality metrics
â”‚   â””â”€â”€ plots/                  #    ðŸ“Š Visualizations & charts
â”‚       â”œâ”€â”€ eda_plots/          #    EDA visualization outputs
â”‚       â”œâ”€â”€ model_performance/  #    Model evaluation charts
â”‚       â””â”€â”€ explainability/     #    XAI visualization outputs
â”‚
â”œâ”€â”€ logs/                       # ðŸ“ Application logs (gitignored content)
â”‚   â””â”€â”€ .gitignore              #    Log files exclusion rules
â”‚
â”œâ”€â”€ .github/workflows/          # ðŸš€ CI/CD automation (GitHub Actions)
â”‚   â””â”€â”€ ci.yml                  #    Test, lint, & deployment pipeline
â”‚
â”œâ”€â”€ .venv/                      # ðŸ Virtual environment (gitignored)
â”‚   â””â”€â”€ ...                     #    Python 3.11.13 with all dependencies installed
â”‚
â”œâ”€â”€ pyproject.toml              # ðŸ“‹ Modern Python packaging configuration
â”œâ”€â”€ requirements.txt            # ðŸ“¦ Production dependencies
â”œâ”€â”€ PROJECT_PLAN.md             # ðŸ“‹ Detailed implementation roadmap
â”œâ”€â”€ IMPLEMENTATION_CHECKLIST.md # âœ… Task tracking with priorities
â”œâ”€â”€ LICENSE                     # ðŸ“„ MIT License
â”œâ”€â”€ .pre-commit-config.yaml     # ðŸ” Pre-commit hooks for code quality
â”œâ”€â”€ .gitignore                  # ðŸ“„ Git ignore patterns
â””â”€â”€ README.md                   # ï¿½ This file
```

**ðŸŽ¯ Current Implementation Status:**
- âœ… **Infrastructure Complete**: Professional package structure & tooling
- âœ… **Device Optimization**: Multi-platform device detection and acceleration  
- âœ… **Dataset Ready**: GoEmotions dataset downloaded (211,225 samples, 28 emotions)
- âœ… **Environment Setup**: Virtual environment with all ML dependencies
- âœ… **Phase 1 Complete**: Data preprocessing pipeline (99.90% quality retention)
- âœ… **Phase 2 Complete**: Baseline modeling (TF-IDF + LogReg, F1-macro: 0.161)
- ðŸš§ **Next Phase**: Transformer fine-tuning (DistilRoBERTa target: F1-macro >0.6)

**Key Design Principles:**
- **Cross-Platform Development**: Optimized for various hardware configurations
- **Separation of Concerns**: Each directory has a single, clear responsibility
- **Scalability**: Structure supports growing from prototype to production  
- **Reproducibility**: Configuration management & environment isolation
- **Collaboration**: Clear testing, documentation & contribution workflows

> **ðŸš¨ IMPORTANT - Data vs Code Separation:**
> - `emotion_xai/data/` = **Python modules** for data processing (code)
> - `data/` (project root) = **Actual dataset files** (CSV, JSON, etc.)
> - This follows best practices: code is installable, data stays with project

> **ðŸ“Š Dataset Information:**
> - **GoEmotions**: 211,225 Reddit comments with 28 emotion labels
> - **Multi-label**: Average 1.18 emotions per comment
> - **Diversity**: Comments from 483 different subreddits
> - **Quality**: Human-annotated for research purposes

## Development

### Setting Up Development Environment

1. Clone the repository:
```bash
git clone https://github.com/Petlaz/emotion-xai-project.git
cd emotion-xai-project
```

2. Create virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install in development mode:
```bash
pip install -e ".[dev]"
```

4. Install pre-commit hooks:
```bash
pre-commit install
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=emotion_xai --cov-report=html

# Run specific test types
pytest tests/unit/          # Unit tests only
pytest tests/integration/   # Integration tests only
```

### Code Quality

```bash
# Format code
black emotion_xai tests

# Sort imports
isort emotion_xai tests

# Lint code
flake8 emotion_xai tests

# Type checking
mypy emotion_xai
```

## CLI Usage

The package provides a command-line interface for common tasks:

```bash
# Test device optimizations (automatic CUDA/MPS/CPU detection)
python emotion_xai/utils/device.py

# Train baseline model with optimized settings
emotion-xai train-baseline --data-path data/raw/goemotions.csv --text-column text

# Train transformer model with automatic device detection
emotion-xai train-transformer --model-name distilroberta-base --epochs 3 --batch-size 16

# Download GoEmotions dataset
python scripts/download_goemotions.py

# Show help for all available commands
emotion-xai --help
```

### Development Commands

```bash
# Verify device optimizations
python -c "from emotion_xai.utils.device import resolve_device; print('Device:', resolve_device())"

# Check dataset status
python -c "import pandas as pd; df = pd.read_csv('data/raw/goemotions.csv'); print(f'Dataset: {len(df):,} samples ready')"

# Run tests
pytest tests/

# Code quality checks
black emotion_xai tests && isort emotion_xai tests && flake8 emotion_xai tests
```

## Documentation

- [Getting Started](docs/getting_started.md)
- [User Guide](docs/user_guide.md)
- [Development Guide](docs/development.md)
- [API Reference](docs/api_reference.md)

## Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Project Progress Status

### âœ… Completed Phases

**Phase 1: Data Preprocessing & EDA**
- GoEmotions dataset integration (211,225 samples, 28 emotions)
- Comprehensive data quality assessment (99.90% retention rate)
- Text cleaning pipeline with conservative/aggressive approaches
- Interactive visualizations and statistical analysis

**Phase 2: Baseline Modeling**
- TF-IDF feature extraction with optimization
- One-vs-Rest Logistic Regression for multi-label classification
- Comprehensive evaluation framework (F1-macro: 0.161)
- Model persistence and artifact management
- Complete notebook implementation (`notebooks/02_modeling.ipynb`)

### ðŸš€ Next Phase: Transformer Fine-tuning

**Target Goals:**
- DistilRoBERTa fine-tuning for emotion classification
- Target performance: F1-macro > 0.6 (4x improvement over baseline)
- Multi-label classification head with label smoothing
- Comprehensive comparison with baseline model

## Acknowledgments

- Built with [Transformers](https://huggingface.co/transformers/) by Hugging Face
- Uses [SHAP](https://github.com/slundberg/shap) for explainable AI
- Clustering powered by [UMAP](https://umap-learn.readthedocs.io/) and [HDBSCAN](https://hdbscan.readthedocs.io/)
- Web interface built with [Gradio](https://gradio.app/)
- Dataset: [GoEmotions](https://github.com/google-research/google-research/tree/master/goemotions) by Google Research