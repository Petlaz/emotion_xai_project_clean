# **Project:** Explainable AI for Emotion Detection in Social Media Text

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)

A comprehensive package for analyzing social media text using transformer models, explainable AI techniques, and clustering for theme discovery. This project implements multi-label emotion classification with state-of-the-art transformers and provides interpretable insights through explainable AI.

## ğŸ¯ Project Overview

### ğŸ† Complete 6-Phase Implementation
- âœ… **Phase 1**: Data Processing (GoEmotions dataset, 211K samples)
- âœ… **Phase 2**: Baseline Modeling (TF-IDF + Logistic Regression)
- âœ… **Phase 3**: Transformer Fine-tuning (DistilRoBERTa, F1-macro 0.196)
- âœ… **Phase 4**: Explainable AI (SHAP, LIME, attention visualization)
- âœ… **Phase 5**: Clustering Analysis (UMAP + HDBSCAN theme discovery)
- âœ… **Phase 6**: Interactive Web Interface (Gradio + HF Spaces ready)

### Features
- **ğŸ¤– Multi-label emotion classification** using fine-tuned DistilRoBERTa (82M parameters)
- **ğŸ” Explainable AI** with SHAP and LIME explanations for model interpretability  
- **ğŸ“Š Theme discovery** through clustering analysis using UMAP + HDBSCAN
- **ğŸŒ Interactive web interface** built with Gradio - **LIVE & READY FOR DEPLOYMENT!**
- **ğŸ“ˆ Comprehensive evaluation** metrics and visualizations with 4-decimal precision
- **ğŸš€ Production-ready** with Hugging Face Spaces deployment support
- **âš¡ Instant launch** with pre-loaded examples and public sharing capability

### Dataset
- **GoEmotions**: 211,225 Reddit comments with 28 emotion labels
- **Multi-label classification**: Comments can have multiple emotions
- **Processed data**: 147K training, 21K validation, 42K test samples

### Performance Achievements
- **âœ… Baseline Model**: F1-macro 0.161 (TF-IDF + Logistic Regression) 
- **âœ… Production Model**: F1-macro 0.196 (19.6% - DistilRoBERTa fine-tuned)
- **âœ… Interactive Interface**: Gradio web app with instant launch capability
- **âœ… Deployment Ready**: Hugging Face Spaces compatible with public sharing

## Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/Petlaz/emotion_xai_project_clean.git
cd emotion_xai_project

# Install dependencies
pip install -r requirements.txt

# Optional: Install in development mode
pip install -e .
```

### Basic Usage

```python
from emotion_xai.utils.device import resolve_device
from emotion_xai.data.preprocessing import load_dataset, prepare_features
from emotion_xai.models.baseline import BaselineModel
from emotion_xai.explainability.explanations import explain_with_shap

# Setup device optimization (automatic detection: CUDA/MPS/CPU)
device = resolve_device()

# Load GoEmotions dataset (211,225 samples with 28 emotion labels)
data = load_dataset("data/raw/goemotions.csv")
features = prepare_features(data, "text")

# Train baseline model (TF-IDF + Logistic Regression)
model = BaselineModel()
model.fit(train_texts, train_labels)

# Evaluate model performance (Current: F1-macro 0.161)
metrics = model.evaluate(val_texts, val_labels)
print(f"F1-macro: {metrics['f1_macro']:.3f}")

# Generate explanations
explanations = explain_with_shap(model, sample_texts)
```

## ğŸ”¥ Production Transformer Training

### Quick Training Options

```bash
# Option 1: Using the runner script (recommended)
./run_production_training.sh test    # Quick test (5K samples, ~5-10 min)
./run_production_training.sh full    # Full training (147K samples, ~30-60 min)

# Option 2: Direct Python execution  
python scripts/train_transformer_production.py --config configs/test_training.json
python scripts/train_transformer_production.py --config configs/production_training.json

# Option 3: Resume from checkpoint
python scripts/train_transformer_production.py \
  --config configs/production_training.json \
  --resume models/distilroberta_production_*/checkpoint-1500
```

### Current Best Model
- **âœ… Production Model**: `models/distilroberta_production_20251130_044054/`
- **ğŸ† Training Complete**: 6,500/11,540 steps (56% of 5 epochs completed)
- **ğŸ¯ Performance**: F1-macro 19.6%, F1-micro 30.4%, Hamming Acc 96.2%
- **ğŸ“ˆ Achievement**: 87% loss reduction (0.695 â†’ 0.089), 1.2x baseline improvement

## ğŸ“Š Project Structure

```
emotion_xai_project/
â”œâ”€â”€ ğŸ“Š data/                     # Dataset and processed features
â”‚   â”œâ”€â”€ raw/                     # Original GoEmotions data
â”‚   â””â”€â”€ processed/               # Cleaned and split datasets
â”œâ”€â”€ ğŸ“” notebooks/                # Jupyter analysis notebooks (clean structure)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb    # âœ… EDA and data quality analysis
â”‚   â”œâ”€â”€ 02_modeling.ipynb           # âœ… Baseline model development
â”‚   â”œâ”€â”€ 03_finetuning.ipynb         # âœ… Transformer model training
â”‚   â”œâ”€â”€ 04_explainability.ipynb     # âœ… Production XAI analysis
â”‚   â””â”€â”€ 05_clustering_analysis.ipynb # âœ… Clustering & theme discovery
â”œâ”€â”€ ğŸ¤– models/                   # Trained model artifacts
â”‚   â”œâ”€â”€ distilroberta_production_20251130_044054/  # âœ… Best production model
â”‚   â”œâ”€â”€ saved_models/            # Baseline model artifacts
â”‚   â””â”€â”€ cluster_embeddings/      # âœ… Clustering pipeline & embeddings cache
â”œâ”€â”€ ğŸ”§ scripts/                  # Production scripts and utilities
â”‚   â”œâ”€â”€ train_transformer_production.py  # Main training script
â”‚   â”œâ”€â”€ use_trained_model.py     # Model inference utilities
â”‚   â”œâ”€â”€ download_goemotions.py   # Dataset download utility
â”‚   â””â”€â”€ test_*.py               # Various testing scripts
â”œâ”€â”€ âš™ï¸  config/                   # General application configurations (YAML)
â”‚   â”œâ”€â”€ production.yaml          # Production deployment settings
â”‚   â”œâ”€â”€ development.yaml         # Development environment config
â”‚   â”œâ”€â”€ default.yaml            # Default configuration settings
â”‚   â””â”€â”€ mac_optimizations.yaml   # Mac M1/M2 specific optimizations
â”œâ”€â”€ ï¿½ results/                  # Training results and visualizations
â”‚   â”œâ”€â”€ metrics/                 # Performance metrics and statistics
â”‚   â”œâ”€â”€ plots/                   # All generated visualizations
â”‚   â””â”€â”€ clustering_analysis_*.json # âœ… Clustering analysis results
â”œâ”€â”€ ğŸ“¦ emotion_xai/              # Core library package
â”‚   â”œâ”€â”€ data/                    # âœ… Data processing utilities
â”‚   â”œâ”€â”€ models/                  # âœ… Model implementations
â”‚   â”œâ”€â”€ explainability/         # âœ… XAI explanations (SHAP/LIME)
â”‚   â”œâ”€â”€ clustering/             # âœ… Theme discovery & clustering pipeline
â”‚   â”œâ”€â”€ utils/                  # âœ… Utility functions and helpers
â”‚   â””â”€â”€ cli.py                  # Command-line interface
â”œâ”€â”€ ğŸŒ app/                      # âœ… Web interface (Complete)
â”‚   â”œâ”€â”€ gradio_app.py           # Full-featured Gradio application (434 lines)
â”‚   â””â”€â”€ __init__.py            # Package initialization
â”œâ”€â”€ ğŸš€ app.py                   # âœ… HF Spaces entry point (production ready)
â”œâ”€â”€ ğŸ“‹ requirements_gradio.txt   # âœ… Gradio deployment dependencies  
â”œâ”€â”€ ğŸ“š README_HF_SPACES.md      # âœ… Hugging Face Spaces documentation
â”œâ”€â”€ ğŸ³ docker/                   # Containerization
â”‚   â”œâ”€â”€ Dockerfile              # Production container setup
â”‚   â””â”€â”€ requirements.txt        # Docker-specific dependencies
â”œâ”€â”€ ğŸ“š docs/                     # Documentation (organized)
â”‚   â”œâ”€â”€ README.md               # Documentation overview
â”‚   â”œâ”€â”€ project_plan.md         # Complete project plan
â”‚   â”œâ”€â”€ documentation_report.md # Comprehensive completion report
â”‚   â”œâ”€â”€ development.md          # Development setup guide
â”‚   â”œâ”€â”€ getting_started.md      # Getting started guide
â”‚   â””â”€â”€ mac_optimization.md     # Mac M1/M2 optimization guide
â”œâ”€â”€ ğŸ§ª tests/                    # Test suite
â”‚   â”œâ”€â”€ conftest.py             # Test configuration
â”‚   â”œâ”€â”€ fixtures/               # Test fixtures
â”‚   â”œâ”€â”€ unit/                   # Unit tests
â”‚   â””â”€â”€ integration/            # Integration tests
â”œâ”€â”€ ğŸ“„ logs/                     # Application logs directory
â””â”€â”€ ğŸ”§ Configuration Files       # Project configuration
    â”œâ”€â”€ requirements.txt         # Main Python dependencies
    â”œâ”€â”€ pyproject.toml          # Package configuration
    â”œâ”€â”€ setup.cfg               # Setup tools configuration
    â”œâ”€â”€ MANIFEST.in             # Package manifest
    â”œâ”€â”€ LICENSE                 # Project license
    â”œâ”€â”€ CHANGELOG.md            # Version history
    â”œâ”€â”€ CONTRIBUTING.md         # Contribution guidelines
    â”œâ”€â”€ .gitignore              # Git ignore patterns
    â””â”€â”€ run_production_training.sh # Production training script
```

## ğŸ” Model Usage

### Using Trained Models

```python
# Load the trained model for inference
from scripts.use_trained_model import EmotionPredictor

# Initialize predictor with best model
predictor = EmotionPredictor("models/distilroberta_production_20251130_044054")

# Single prediction
emotions = predictor.predict("I love this product but the delivery was slow")
print(emotions)  # {'joy': 0.85, 'disappointment': 0.73, ...}

# Batch prediction
results = predictor.predict_batch([
    "Amazing customer service!",
    "The product broke after one day",
    "Decent quality for the price"
])

# Interactive demo
predictor.run_interactive_demo()  # Launches Gradio interface
```

### Web Interface

Launch the interactive Gradio interface:

```bash
python app/gradio_app.py
# OR
python app.py  # HF Spaces entry point
```

Access at `http://localhost:7860` for:
- Real-time emotion prediction with 4-decimal precision
- Interactive Plotly visualizations
- Model explanations with SHAP/LIME
- Batch processing capabilities
- Professional UI with instant launch examples

### ğŸš€ Hugging Face Spaces Deployment

Ready for one-click deployment to Hugging Face Spaces:

1. **Files Ready**:
   - âœ… `app.py` - Main entry point
   - âœ… `requirements_gradio.txt` - Dependencies
   - âœ… `README_HF_SPACES.md` - Spaces documentation

2. **Deploy Command**:
```bash
# From your HF Spaces repository
git add .
git commit -m "Deploy Emotion-XAI app"
git push
```

3. **Features**:
   - âœ… Instant launch (<30s)
   - âœ… Pre-loaded examples
   - âœ… Public sharing capability
   - âœ… Production DistilRoBERTa model (82M params)
   - âœ… 4-decimal precision scores

## ğŸ§  Explainable AI

### SHAP Explanations

```python
from emotion_xai.explainability.explanations import explain_with_shap

# Generate SHAP explanations for predictions
explanations = explain_with_shap(
    model=predictor.model,
    tokenizer=predictor.tokenizer, 
    text="The service was excellent but expensive",
    top_k_emotions=5
)

# Visualize feature importance
explanations.plot()    # Shows word-level contributions
```

### LIME Explanations

```python
from emotion_xai.explainability.explanations import explain_with_lime

# Generate LIME explanations
lime_exp = explain_with_lime(
    predictor=predictor,
    text="Fast shipping, great quality product!",
    num_features=10
)

lime_exp.show_in_notebook()  # Interactive visualization
```

## ğŸ“ˆ Performance Monitoring

### Training Progress

Monitor training with built-in logging:

```python
# Check latest training metrics
from pathlib import Path
import json

# Load final training results
results_path = Path("results/production_training/production_results_20251130_074958.json")
with open(results_path) as f:
    results = json.load(f)
    
print(f"Final F1-macro: {results['test_results']['f1_macro']:.4f}")
print(f"Training duration: {results['training_info']['duration_minutes']:.1f} minutes")
print(f"Model location: {results['model_path']}")
```

## ğŸ› ï¸ Development

### Setting Up Development Environment

1. Clone the repository:
```bash
git clone https://github.com/Petlaz/emotion-xai-project_clean.git
cd emotion-xai-project
```

2. Create virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install in development mode:
```bash
pip install -e ".[dev]"
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=emotion_xai --cov-report=html

# Run specific test types
pytest tests/unit/          # Unit tests only
pytest tests/integration/   # Integration tests only
```

### Code Quality

```bash
# Code formatting
black emotion_xai/ scripts/ tests/
isort emotion_xai/ scripts/ tests/

# Linting  
flake8 emotion_xai/ scripts/ tests/
mypy emotion_xai/

# Security check
bandit -r emotion_xai/
```

## CLI Usage

The package provides a command-line interface for common tasks:

```bash
# Test device optimizations (automatic CUDA/MPS/CPU detection)
python emotion_xai/utils/device.py

# Train baseline model with optimized settings
emotion-xai train-baseline --data-path data/raw/goemotions.csv --text-column text

# Train transformer model with automatic device detection
emotion-xai train-transformer --model-name distilroberta-base --epochs 3 --batch-size 16

# Download GoEmotions dataset
python scripts/download_goemotions.py
```

## ğŸš€ Deployment

### Hugging Face Spaces (Recommended)

**âœ… Ready for one-click deployment!**

**Pre-deployment Checklist:**
- âœ… `app.py` - HF Spaces entry point 
- âœ… `requirements_gradio.txt` - Complete dependencies
- âœ… `README_HF_SPACES.md` - Spaces metadata and documentation
- âœ… Gradio interface with instant launch capability
- âœ… Production model included (82M parameters)
- âœ… 4-decimal precision for emotion scores
- âœ… Public sharing enabled with professional UI

**Deploy Steps:**
1. Create new Space on Hugging Face
2. Upload project files
3. Set Space to use `app.py` as main file
4. App launches automatically with <30s startup time

### Docker Support

```bash
# Build the Docker image
docker build -t emotion-xai .

# Run the container
docker run -p 7860:7860 emotion-xai

# With GPU support
docker run --gpus all -p 7860:7860 emotion-xai
```

### Production Features

The system is designed for production with:
- **âœ… Scalable inference** with batch processing
- **âœ… Public API** via Gradio sharing links
- **âœ… Model versioning** with checkpoint management
- **âœ… Real-time monitoring** with comprehensive metrics
- **âœ… Professional UI** with instant examples and explanations
- **âœ… Cross-platform** compatibility (CUDA/MPS/CPU auto-detection)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes with tests
4. Run quality checks (`black`, `flake8`, `pytest`)
5. Commit changes (`git commit -m 'Add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Acknowledgments

- **GoEmotions Dataset**: Google Research for the comprehensive emotion dataset
- **Hugging Face**: Transformers library and model hub
- **SHAP/LIME**: Explainable AI framework contributions
- **Gradio**: Interactive ML interface framework

## ğŸ“ Support

For questions, issues, or contributions:
- **GitHub Issues**: [Create an issue](https://github.com/Petlaz/emotion_xai_project_clean/issues)
- **Documentation**: Check the `docs/` directory for detailed guides
- **Examples**: See `notebooks/` for usage examples

---

## ğŸš€ Live Demo

**Try the live demo**: [Emotion-XAI Web App](https://huggingface.co/spaces/your-username/emotion-xai) (Coming Soon!)

**Status**: âœ… **PROJECT COMPLETE** - All 6 phases implemented with production-ready Gradio interface, ready for Hugging Face Spaces deployment!